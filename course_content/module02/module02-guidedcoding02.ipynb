{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jupyter.org/assets/main-logo.svg\" heigt=60> <font size=\"14\" color=grey>  DHI Campus - Jupyter Training</font>  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data into notebooks - guided coding session \n",
    "\n",
    "\n",
    "## Python for Environmental Modellers: Essential Libraries \n",
    "\n",
    "This lecture introduces the participant to a number of essential libraries useful for environmental modelling:\n",
    "\n",
    "**Pandas** is a library to work with tabulated data like Excel files or databases. Shape-files and other spatials data  are handled with the \n",
    "\n",
    "**Geopandas** extension.\n",
    "<img src=\"figures/panda.jpg\" width=\"450\">\n",
    "\n",
    "\n",
    "**Matplotlib** is the common workhorse for visualization. It provides code-efficient commands to create publishing-ready figures. A number of of libries (including Pandas or TimML) rely on matplotlib for visualization.\n",
    "\n",
    "These libraries are taught first as they are fundamental for the subsequent course modules.\n",
    "\n",
    "The participant is encouraged to have a look at a number of other Python libraries common in the scientific communities, which cannot be handled in the course of this traning:\n",
    "\n",
    "+ numpy (numerical computation, support for large arrays of data)\n",
    "+ scipy (scientific computation - integration, linear algebra, optimization, ...)\n",
    "+ statsmodels (statistics - regression, ...)\n",
    "+ scikit-learn (machine learning)\n",
    "\n",
    "**Further Reading**: This course restricts itself to the absolutely required basics. For the interested participant, we recommend the textbook *Python for Data Analysis* by Wes McKinney (O'Reily, ISBN 978-1-491-95766-0) \n",
    "\n",
    "<img src=\"figures/python-for-data-analysis-cover.jpg\" width=\"250\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8> --- Part 1 --- </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "### Import libraries\n",
    "to import a library in python one can use the command `import libraryname`.\n",
    "It is also possible to assign an alias to the library.\n",
    "In the following we will import the pandas library under the alias pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from files\n",
    "\n",
    "Large datasets are usually imported from files. This example uses an Excel file.\n",
    "\n",
    "Other input formats common to modelling can be imported in a very similar way:\n",
    "\n",
    "    df_csv = pd.read_csv()\n",
    "    df_dat = pd.read_csv(delim_whitespace=True)\n",
    "    df_sql = pd.read_sql()\n",
    "    df_pickle = pd.read_pickle()\n",
    "    \n",
    "pickle is a binary format for python objects. Useful if working with notebooks that require long processing times (allows to make intermediary saves and to avoid re-running the complete notebook after restarting Jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to import the excel file located under ../../data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Pandas DataFrame provides some methods e.g. for data exploration .methodname(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Pandas DataFrame provides some methods e.g. for data exploration. \n",
    "# Try the describe method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data from files\n",
    "\n",
    "...works exactly the other way around as loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to files works the other way around. Let's save the dataframe as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting stacked tables\n",
    "\n",
    "The XLSX file contains time series that have been exported from the FEFLOW GUI. \n",
    "\n",
    "It has the form of a stacked table, meaning that data of all times and observation points appear in the same table. This is a quite common of format in model outputs in general, however not really useful for processing.\n",
    "\n",
    "Pandas provides a built-in method to tabulate the data with an individual colunm per observation bore. This is done by using the `pivot`-function\n",
    "\n",
    "Note this useful if all observation points share the same time steps (as they usually do in model output). For measurement data with usually asynchrounous data, the data should be resampled if tabulation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tabulate the data, provide the names of the coulnms that contains \n",
    "# 1. the index (here: X, time), \n",
    "# 2. the values (here: Y) and \n",
    "# 3. the columns (here: Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "To resample a DataFrame (or DataSeries), its index field must be of type DateTime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: how to generate datetime objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the index axis from a time to a calendar axis, we create a new column of type DateTime and set it as the new index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a start date and create a new column of type DateTime \n",
    "# create a new column \"Calendar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \"Calendar\" as new index and replace old index with it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual resampling is done with the `resample` method. The first argument is the resampling rule (`D` stands for Daily values). The method returns an object, on that we need to apply a accumulation operation. In this case, we use the `mean` value of all measured heads in a day, which makes sense for head measurements.\n",
    "\n",
    "(A different option would be `.resample(\"D\").sum()`, for example when downsampling rainfall or pumping rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to average daily values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gapfilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample and remove gaps by dropping all rows that contain NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample and remove gaps by interpolating all rows that contain NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8> --- Part 2 --- </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data\n",
    "\n",
    "### choosing columns\n",
    "\n",
    "Large tabulated data sets often have impractibly large numbers of columns. Unless you save and open them in Excel, they need to be reduced to a subset to show them in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a single column by column name (returns a DataSeries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing rows\n",
    "\n",
    "What works for columns also works for rows. The DataFrame method .iloc you can select either single rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose entry number 5 (caution, indexing starts at 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or slice, because the index columns are ordered, it allows you to provide (row) ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose slice of first five entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A datetime-axis can be conveniently addressed by using ISO-Datestrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose all rows of May 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Some further notes on complex indexing\n",
    "\n",
    "For more complex indexing, please see the following commands\n",
    "\n",
    "+ `DataFrame.at[]`: Access a single value for a row/column label pair\n",
    "+ `DataFrame.loc[]`: Access group of rows and columns by labels (or boolean arrays)\n",
    "+ `DataFrame.iloc[]`: Access group of rows and columns by integer position(s)\n",
    "+ `DataFrame.xs[]`: Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.\n",
    "\n",
    "**Note:** To assign data to slices of a dataframe, .loc[] must be used!\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<font size=8> --- Part 3 --- </font>\n",
    "\n",
    "## Simple plotting\n",
    "\n",
    "Pandas provides easy access to matplotlib-style plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data contained in the DataFrame with method .plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on visualization and customization of plots in the next module.."
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
